"""
MapPLUTO å¤šå¹´ä»½æ•´åˆè„šæœ¬ï¼ˆå«å‡ ä½•å­—æ®µï¼‰
------------------------------------------------------
åŠŸèƒ½ï¼š
1. è‡ªåŠ¨è¯»å– 2016â€“2025 å¹´çš„ MapPLUTO shapefileï¼›
2. è‡ªåŠ¨è¯†åˆ«å¹´ä»½ï¼›
3. å¤„ç† 2016â€“2017 å¹´çš„åˆ†è¡Œæ”¿åŒºç»“æ„ï¼›
4. ä¿ç•™æ ¸å¿ƒå­—æ®µ + geometryï¼›
5. è¾“å‡ºç»Ÿä¸€ GeoJSON æ–‡ä»¶ï¼Œå¯ç”¨äºåç»­ç©ºé—´åˆ†æä¸å¯è§†åŒ–ã€‚
"""

import geopandas as gpd
import pandas as pd
import glob
import os
import re

# ========== å‚æ•° ==========
DATA_DIR = "C:/Users/Jeffery/Desktop/çŸ³è¿›å¤§ä½œä¸š/MapPluto"      # ä¿®æ”¹ä¸ºä½ çš„ MapPLUTO æ ¹ç›®å½•
OUTPUT_FILE = "outputs/pluto_all_years.geojson"

# å¸¸ç”¨å­—æ®µç»Ÿä¸€æ˜ å°„
COLUMN_MAP = {
    "BBL": "bbl",
    "bbl": "bbl",
    "LandUse": "land_use",
    "landuse": "land_use",
    "YearBuilt": "year_built",
    "yearbuilt": "year_built",
    "BldgArea": "bldg_area",
    "bldgarea": "bldg_area",
    "LotArea": "lot_area",
    "lotarea": "lot_area",
    "UnitsRes": "units_res",
    "unitsres": "units_res"
}

# ========== è¯»å–å‡½æ•° ==========
def load_citywide(path, year):
    """è¯»å–å•ä¸€ citywide shapefile"""
    print(f"ğŸ“‚ è¯»å– {year} å¹´ citywide æ•°æ®: {path}")
    gdf = gpd.read_file(path)
    gdf.columns = [c.lower() for c in gdf.columns]
    gdf.rename(columns=COLUMN_MAP, inplace=True)
    gdf["year"] = year
    return gdf


def load_by_borough(folder, year):
    """è¯»å–åˆ†è¡Œæ”¿åŒºçš„ shapefile å¹¶åˆå¹¶"""
    print(f"ğŸ“‚ è¯»å– {year} å¹´åˆ†è¡Œæ”¿åŒºæ•°æ®: {folder}")
    borough_shps = glob.glob(os.path.join(folder, "*/*.shp"))
    if not borough_shps:
        borough_shps = glob.glob(os.path.join(folder, "*.shp"))
    parts = []
    for shp in borough_shps:
        try:
            gdf = gpd.read_file(shp)
            gdf.columns = [c.lower() for c in gdf.columns]
            gdf.rename(columns=COLUMN_MAP, inplace=True)
            parts.append(gdf)
            print(f"  âœ… è½½å…¥ {os.path.basename(shp)} ({len(gdf)} æ¡)")
        except Exception as e:
            print(f"  âš ï¸ æ— æ³•è¯»å– {shp}: {e}")
    if parts:
        merged = pd.concat(parts, ignore_index=True)
        merged["year"] = year
        return gpd.GeoDataFrame(merged, geometry="geometry", crs="EPSG:2263")
    else:
        return None


# ========== ä¸»ç¨‹åº ==========
all_gdfs = []

for folder in sorted(os.listdir(DATA_DIR)):
    year_match = re.search(r"20?(\d{2})", folder)
    if not year_match:
        continue
    year = int("20" + year_match.group(1))

    folder_path = os.path.join(DATA_DIR, folder)

    # 2016â€“2017 åˆ†è¡Œæ”¿åŒºï¼Œä¹‹åä¸º citywide
    if year <= 2017:
        gdf = load_by_borough(folder_path, year)
    else:
        # æŸ¥æ‰¾ shapefile
        shp_files = glob.glob(os.path.join(folder_path, "*.shp"))
        if not shp_files:
            print(f"âš ï¸ æœªæ‰¾åˆ° {year} å¹´ shapefile")
            continue
        gdf = load_citywide(shp_files[0], year)

    if gdf is not None:
        all_gdfs.append(gdf)

# åˆå¹¶
if not all_gdfs:
    print("âŒ æœªè¯»å–åˆ°ä»»ä½•æœ‰æ•ˆæ•°æ®ã€‚")
else:
    gdf_all = pd.concat(all_gdfs, ignore_index=True)

    # åæ ‡è½¬æ¢ä¸º WGS84ï¼ˆç»çº¬åº¦ï¼‰
    gdf_all = gdf_all.to_crs(epsg=4326)

    # ä»…ä¿ç•™å…³é”®å­—æ®µ
    core_fields = ["bbl", "land_use", "year_built", "bldg_area", "lot_area", "units_res", "year", "geometry"]
    for col in core_fields:
        if col not in gdf_all.columns:
            gdf_all[col] = pd.NA

    gdf_all = gdf_all[core_fields]

    # å¯¼å‡º
    os.makedirs("outputs", exist_ok=True)
    gdf_all.to_file(OUTPUT_FILE, driver="GeoJSON")

    print(f"\nâœ… å·²æˆåŠŸè¾“å‡ºç»Ÿä¸€æ–‡ä»¶ï¼š{OUTPUT_FILE}")
    print(f"ğŸ“ æ•°æ®è§„æ¨¡ï¼š{len(gdf_all):,} æ¡åœ°å—è®°å½•")
    print("ğŸŒ åæ ‡ç³»ï¼šEPSG:4326ï¼ˆç»çº¬åº¦ï¼‰")
